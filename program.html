<!DOCTYPE HTML>
<!--
	Photon by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>LHMP 2021 workshop</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">

	<div id="wrapper">

		<!-- Header -->
		<section id="header" height="100px">
			<div class="inner">
				<!-- Nav -->
				<nav>
					<ul>
						<li><a href="#menu">Menu</a></li>
					</ul>
				</nav>
				<span class="symbol"><img width="100px" src="images/lhmp-icon-2021-shadow.svg" alt="" /></span>
				<h2>Program</h2>
			</div>
		</section>

		<!-- Menu -->
		<nav id="menu">
			<h2>Menu</h2>
			<ul>
				<li><a href="index.html">Home</a></li>
				<li><a href="program.html">Program</a></li>
				<li><a href="call_for_papers.html">Call for Papers</a></li>
				<li><a href="challenge.html">Challenge</a></li>
				<li><a href="past_events.html">Past Events</a></li>
			</ul>
		</nav>


		<section id="one" class="main style1">

			<!-- One -->
			<div class="container">
				The program of this workshop includes 8 talks, spotlight presentations for the selected papers and a
				trajectory prediction challenge.

				In order to account for the diverse time zones of the invited speakers, the workshop will be split into
				the morning and the evening session in the Central European Summer Time zone (CEST). The talks will be
				recorded and all materials will be available on this website.</p>

				<h3>Morning session</h3>

				<div class="table-wrapper">
					<table>
						<thead>
							<tr>
								<th>Time CEST (PST)</th>
								<th>Speaker</th>
								<th>Topic</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>11:00 - 11:10 (02:00 - 02:10 AM)</td>
								<td>Organizers</td>
								<td>Welcome and Introduction</td>
							</tr>
							<tr>
								<td>11:10 - 11:40 (02:10 - 02:40 AM)</td>
								<td><strong><a href="https://www.monash.edu/engineering/danakulic">Dana
											Kulic</a></strong>, Monash University</td>
								<td>Human motion prediction from demonstrations and interaction</td>
							</tr>
							<tr>
								<td colspan="3">Understanding human movement is an important topic in biomechanics,
									human-robot interaction and rehabilitation engineering. In this talk, I will first
									describe our recent work on estimating human objectives by observing human actions
									and preferences, including time-varying objectives and and from incomplete
									observations, and illustrate how estimates of human objectives can be used for
									behaviour prediction. Next, I will describe how models of human movement during
									interaction can be estimated in-the-loop and used to guide interaction policy.</td>
							</tr>
							<tr>
								<td>11:40 - 12:10 (02:40 - 03:10 AM)</td>
								<td><strong><a href="https://www.professoren.tum.de/en/haddadin-sami">Sami
											Haddadin</a></strong>, TUM</td>
								<td>Title</td>
							</tr>
							<tr>
								<td colspan="3">Abstract</td>
							</tr>
							<tr>
								<td>12:10 - 12:20 (03:10 - 03:20 AM)</td>
								<td>Break</td>
								<td></td>
							</tr>
							<tr>
								<td>12:20 - 12:50 (03:20 - 03:50 AM)</td>
								<td><strong><a href="https://www.kth.se/profile/lihuiw">Lihui Wang</a></strong>, KTH
								</td>
								<td>Motion Prediction for Human-Robot Collaborative Assembly </td>
							</tr>
							<tr>
								<td colspan="3">Human-robot collaboration has attracted increasing attentions in recent
									years, both in academia and in industry. For example, in human-robot collaborative
									assembly, robots are often required to dynamically change their pre-planned
									trajectories to collaborate with human operators in a shared workspace. However,
									industrial robots used today are controlled by pre-generated rigid codes that cannot
									support effective human-robot collaboration. In response to this need, human motion
									prediction is crucial for both collision avoidance and proactive assistance to
									humans, in addition to multi-modal robot control. Deep learning is used for
									classification, recognition and context awareness identification. Within the
									context, this presentation provides an overview as well as technical treatment on
									motion prediction for human-robot collaboration. Remaining challenges and future
									directions will also be highlighted. </td>
							</tr>
							<tr>
								<td>12:50 - 13:20 (03:50 - 04:20 AM)</td>
								<td><a href="challenge.html">TrajNet++ trajectory prediction challenge</a></td>
								<td></td>
							</tr>
							<tr>
								<td>13:20 - 13:30 (04:20 - 04:30 AM)</td>
								<td>Organizers</td>
								<td>Concluding the first session</td>
							</tr>
						</tbody>
					</table>
				</div>

				<h3>Evening session</h3>

				<div class="table-wrapper">
					<table>
						<thead>
							<tr>
								<th>Time CEST (PST)</th>
								<th>Speaker</th>
								<th>Topic</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>17:00 - 17:10 (08:00 - 08:10 AM)</td>
								<td>Organizers</td>
								<td>Introducing the second session</td>
							</tr>
							<tr>
								<td>17:10 - 17:40 (08:10 - 08:40 AM)</td>
								<td><strong><a href="https://www.hrl.uni-bonn.de/Members/maren">Maren
											Bennewitz</a></strong>, University of Bonn</td>
								<td>Anticipating Human Movements and Foresighted Robot Navigation Using Learned
									Human-Object Interactions</td>
							</tr>
							<tr>
								<td colspan="3">Service robots that help humans in their everyday life should avoid
									interferences with them and adapt their navigation behavior
									accordingly. This requires a robot to anticipate the user's movements
									and to infer where support will be needed. In this talk, I present an
									approach that predicts the user’s navigation goal based on the robot’s
									observations and prior knowledge about typical human transitions
									between objects. Our system then generates a navigation strategy that
									minimizes the robot’s arrival time at the navigation goal and, at the
									same time, complies with the user’s comfort during the movement.</td>
							</tr>
							<tr>
								<td>17:40 - 18:10 (08:40 - 09:10 AM)</td>
								<td><strong><a href="http://www.mit.edu/~jhow/">Jonathan P. How</a></strong>, MIT</td>
								<td>Title</td>
							</tr>
							<tr>
								<td colspan="3">Abstract</td>
							</tr>
							<tr>
								<td>18:10 - 18:20 (09:10 - 09:20 AM)</td>
								<td>Break</td>
								<td></td>
							</tr>
							<tr>
								<td>18:20 - 18:50 (09:20 - 09:50 AM)</td>
								<td><strong><a href="http://elenacorinagrigore.com/">Elena Corina Grigore</a></strong>,
									Motional</td>
								<td>Title</td>
							</tr>
							<tr>
								<td colspan="3">Abstract</td>
							</tr>
							<tr>
								<td>18:50 - 19:20 (09:50 - 10:20 AM)</td>
								<td><strong><a href="http://bensapp.github.io/">Benjamin Sapp</a></strong>, Waymo</td>
								<td>Long term prediction in complex interactive environments</td>
							</tr>
							<tr>
								<td colspan="3">Long-term human motion prediction is a critical component of scalable
									autonomous driving systems. There has been a multitude of core modeling improvements
									for this task in recent years, in large part fueled by popular public benchmarks.
									However, existing datasets, metrics, and output representations leave much to be
									desired in their ability to capture interactions between agents. In this talk, we go
									over recent advances in modeling, datasets, evaluation and output representations at
									Waymo, with a particular emphasis on modeling interactions.
								</td>
							</tr>
							<tr>
								<td>19:20 - 19:30 (10:20 - 10:30 AM)</td>
								<td>Break</td>
								<td></td>
							</tr>
							<tr>
								<td>19:30 - 20:00 (10:30 - 11:00 AM)</td>
								<td><strong><a href="https://people.eecs.berkeley.edu/~nrhinehart/">Nick
											Rhinehart</a></strong>, UC Berkeley</td>
								<td>Title</td>
							</tr>
							<tr>
								<td colspan="3">Abstract</td>
							</tr>
							<tr>
								<td>20:00 - 20:40 (11:00 - 11:40 AM)</td>
								<td><a href="call_for_papers.html">Paper spotlight presentations</a></td>
								<td></td>
							</tr>
							<tr>
								<td>20:40 - 20:50 (11:40 - 11:50 AM)</td>
								<td>Organizers</td>
								<td>Concluding the second session</td>
							</tr>
						</tbody>
					</table>
				</div>

				<ul class="actions">
					<li><a href="index.html" class="button">Back</a></li>
				</ul>
			</div>

		</section>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>